{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt8VDTQyps3c"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "Before starting, you must click on the \"Copy To Drive\" option in the top bar. Go to File --> Save a Copy to Drive. Name it *'LastName_FirstName_T2.2.ipynb'*. <ins>This is the master notebook so you will not be able to save your changes without copying it !</ins> Once you click on that, make sure you are working on that version of the notebook so that your work is saved.\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6A4G74K2-FV"
      },
      "source": [
        "### In this Colab, we explore the effect of TF Lite Optimization on size, performance, and accuracy on an Image Classification task. For best performance on this Colab make sure you are using a **GPU runtime!** The runtime can be changed by selecting: ```runtime -> change runtime type``` and selecting GPU from the hardware accelerator dropdown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW0PlnQDFOij"
      },
      "source": [
        "### Import necessary libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "D1J15Vh_1Jih"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkBd_mxNWIrg"
      },
      "source": [
        "We import the following libraries -\n",
        "\n",
        "1.   [tensorflow](https://www.tensorflow.org/) - open source library to develop and train ML models\n",
        "2. [tensorflow_hub](https://www.tensorflow.org/hub) - repository of trained machine learning models\n",
        "3. [tensorflow_datasets](https://www.tensorflow.org/datasets) - a collection of ready-to-use datasets\n",
        "4.   [matplotlib](https://matplotlib.org/) - visualization of data in Python\n",
        "5.   [numpy](https://numpy.org/) - scientific computing in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqNRQoc7W17k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mBYtV-TWr-S"
      },
      "source": [
        "### Load Cats vs Dogs Dataset\n",
        "\n",
        "The Dataset is loaded and split into train, validation, and test datasets based on the specified split. Train - 80%, Validation - 10%, and Test - 10%.\n",
        "\n",
        "You can read more about the API [here](https://www.tensorflow.org/datasets/api_docs/python/tfds/load)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BuYItI7WcJJ"
      },
      "outputs": [],
      "source": [
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
        "\n",
        "# load in our dataset\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "# display how much data we have\n",
        "num_examples = metadata.splits['train'].num_examples\n",
        "num_classes = metadata.features['label'].num_classes\n",
        "print()\n",
        "print(\"Number of data samples:\", num_examples)\n",
        "print(\"Number of classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2Bl1nj0rL1j"
      },
      "source": [
        "### Visualize Training Examples\n",
        "\n",
        "Let's visualize a few examples. We see that the dataset contains images of different sizes! We will convert them to (224, 224, 3) sized images later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aiQLw5kq8Nx"
      },
      "outputs": [],
      "source": [
        "vis = tfds.visualization.show_examples(raw_train, metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STCItgvXDQW8"
      },
      "source": [
        "We reshape the images to (224, 224, 3) and split the dataset into batches to reduce memory requirement. Here's the documentation for the following - [prefetch](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch), [map](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map), [batch](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch), [shuffle](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle), [take](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTLIRT6oDUGL"
      },
      "outputs": [],
      "source": [
        "# format images to have normalized pixels\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (224, 224)) / 255.0\n",
        "    return  image, label\n",
        "\n",
        "\n",
        "# split the data in training, validation, and test datasets\n",
        "BATCH_SIZE = 32\n",
        "train_batches = raw_train.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = raw_test.map(format_image).batch(1)\n",
        "\n",
        "print(\"Number of training batches:\", len(train_batches))\n",
        "\n",
        "# display the shape of our data\n",
        "for image_batch, label_batch in train_batches.take(1):\n",
        "    pass\n",
        "\n",
        "\n",
        "print(\"Shape of one batch of images:\", image_batch.shape)\n",
        "print(\"label example:\", label_batch[10].numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpqPEIbF9lx"
      },
      "source": [
        "### Define pre-trained model\n",
        "\n",
        "We will be using the concept of **Transfer Learning** to train our model - tuning the weights of an already trained model to fit our dataset. We take advantage of the fact that the features learned in the initial few layers by a network on any dataset are fundamental and could be tranferable to other datasets (like lines, basic shapes etc). This prevents us from training our model from scratch which would reduce the amount of time needed for training. You can read more about transfer learning [here](https://machinelearningmastery.com/transfer-learning-for-deep-learning/).\n",
        "\n",
        "Here, we download the weights of a MobileNet model pre-trained on the ImageNet Dataset from TensorFlow Hub. We use these weights to subsequently train our custom neural network. You can read more about this popular neural network model [here](https://arxiv.org/pdf/1801.04381.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inIK227eZbgV"
      },
      "outputs": [],
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280)       # (pre-trained model, input pixel size, output feature vector size)\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mpYLmivzl1Y"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "**Question 1**: Why do we use Transfer Learning?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Uv0gYXpMKe"
      },
      "source": [
        "### Define our model\n",
        "\n",
        "We will extract the feature extractor from the pre-trained model which form the main layers of our model. We will then add a dense layer with the number of neurons equal to the number of classes to complete our model for our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu7Q1cPBp1ba"
      },
      "outputs": [],
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,),\n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=False)\n",
        "\n",
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "\n",
        "\n",
        "# model layers stacked\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgztTXppbdvs"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "**Question 2**: Can you think of why we set the trainable parameter as 'False' for the pre-trained model?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-WpfqEHp7Q1"
      },
      "source": [
        "Let's look at a summary of our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aniAKAkKqAXc"
      },
      "outputs": [],
      "source": [
        "#<YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcyJ8R-gqK3c"
      },
      "source": [
        "Finally, we define our loss and optimizer and compile our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6dQMjg1qJZ2"
      },
      "outputs": [],
      "source": [
        "LOSS = 'sparse_categorical_crossentropy'\n",
        "OPT = 'adam'\n",
        "\n",
        "\n",
        "model.compile(optimizer=OPT,\n",
        "                  loss=LOSS,\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFm6YokEGOew"
      },
      "source": [
        "### Train model\n",
        "Since we are doing transfer learning to fine tune a pre-trained model to our dataset we only need to use 5 Epochs. We will explore transfer learning in detail and study how, why, and where it works later in this course!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFdUvxZUGLji"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "hist = model.fit(train_batches,\n",
        "                 epochs=EPOCHS,\n",
        "                 validation_data=validation_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGdI_yFLd5RA"
      },
      "source": [
        "We see that even with just 5 epochs, our model is doing pretty well! Let's go ahead and save this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEpcBkDldJ_k"
      },
      "source": [
        "### Save Model\n",
        "\n",
        "The saved model cab be found in the File/ tab on the left!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cML-V4yqtuYI"
      },
      "outputs": [],
      "source": [
        "CATS_VS_DOGS_SAVED_MODEL = \"saved_model\"\n",
        "tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsPCTmgdBjw9"
      },
      "source": [
        "##1. Model1: TFLite model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BGe8CF7aruS"
      },
      "source": [
        "\n",
        "In the below code cell, we generate model1.tflite.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gButZXqZt3o4"
      },
      "outputs": [],
      "source": [
        "converter = #<YOUR CODE HERE>\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"/content/\")\n",
        "tflite_model_file = tflite_models_dir/'model1.tflite'\n",
        "print(\"Size of model1:\", tflite_model_file.write_bytes(tflite_model))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlw1xQv3sih_"
      },
      "source": [
        "***Hint:*** Use `tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)` to instantiate the converter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAusukBMgC1y"
      },
      "source": [
        "We see that the tflite model is around 9MB!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhQRNUyuB1vY"
      },
      "source": [
        "## 2. Model2: TFLite model with Dynamic Range Quantization\n",
        "\n",
        "We add the ```converter.optimizations = [tf.lite.Optimize.DEFAULT]``` line. Run the below code to generate model2.tflite, which will have optimizations added -- you should see a much smaller file size. The model weights are now represented as **8-bit precision** values as opposed to **Float32**, therefore creating a 4x reduction in size! Read more [here](https://www.tensorflow.org/lite/performance/post_training_quant).\n",
        "\n",
        "\\\n",
        "\n",
        "**Note:** tf.lite.Optimize has changed and the OPTIMIZE_FOR_SIZE and OPTIMIZE_FOR_LATENCY options are now deprecated and are the same as DEFAULT: https://www.tensorflow.org/api_docs/python/tf/lite/Optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJOT4JXKDa_a"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]   # optimization\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "tflite_models_dir = pathlib.Path(\"/content/\")\n",
        "\n",
        "tflite_model_file = tflite_models_dir/'model2.tflite'\n",
        "tflite_model_file.write_bytes(tflite_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa8MY0YCCMX6"
      },
      "source": [
        "## 3. Model3: TFLite model with Integer Quantization\n",
        "\n",
        "\n",
        "Integer quantization is an optimization strategy that converts **32-bit floating-point** numbers (such as weights and activation outputs) to the nearest **8-bit fixed-point** numbers. We include a representative dataset and set the supported ops as shown. Run the below code to generate model3.tflite which will have optimizations added, along with quantization from the representative dataset. Read more [here](https://www.tensorflow.org/lite/performance/post_training_integer_quant).\n",
        "\n",
        "**Note:** it might be slightly larger than model2.tflite!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3PYcSwPD_ZB"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]    # optimization\n",
        "\n",
        "def representative_data_gen():                          # quantization from representative dataset\n",
        "    for input_value, _ in test_batches.take(100):\n",
        "        yield [input_value]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "tflite_models_dir = pathlib.Path(\"/content/\")\n",
        "\n",
        "tflite_model_file = tflite_models_dir/'model3.tflite'\n",
        "tflite_model_file.write_bytes(tflite_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RTZmndkcZFP"
      },
      "source": [
        "## Inference\n",
        "Now we will test the accuracy of the three models! After you run each model you will get the number of correct predictions and then you can plot some results and see if you notice any wrong predictions!\n",
        "\n",
        "We use the **'Interpreter'** to run inference on our TFLite models!\n",
        "\n",
        "\\\n",
        "\n",
        "**Important Notes:**\n",
        "\n",
        "\n",
        "1.   Changes have been made to the TFLite Interpreter that further optimize it for mobile use at the expense of speed in Colab i.e, these models are optimized for hardware and will run slower on Colab.\n",
        "2.   Inference Time can be truly appreciated when run on actual hardware such as the Raspberry Pi.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsNjuPhxuDOx"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "tflite_model_file = 'model1.tflite'                 # Change the filename here for Model 2 and 3\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "predictions = []\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(100)):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "    test_labels.append(label.numpy()[0])\n",
        "    test_imgs.append(img)\n",
        "\n",
        "score = 0\n",
        "for item in range(0,100):\n",
        "  prediction=np.argmax(predictions[item])\n",
        "  label = test_labels[item]\n",
        "  if prediction==label:\n",
        "    score=score+1\n",
        "\n",
        "print()\n",
        "print(\"Out of 100 predictions I got \" + str(score) + \" correct\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xU_GxN-g1wt"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "**Question 3**: Note down the number of Iterations/second for all 3 models.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "\n",
        "1.   Model1 :\n",
        "2.   Model2 :\n",
        "3.   Model3 :\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fenLYwLpmPC9"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "**Question 4**: Note down the number of correct predictions for all 3 models.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "\n",
        "1.   Model1 :\n",
        "2.   Model2 :\n",
        "3.   Model3 :\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B-sqiZZESjq"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Here, we define a utility function to plot test images with their predictions. We plot the correct predictions with green titles and wring predictions with red titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99XU_yGOEgI3"
      },
      "outputs": [],
      "source": [
        "# Utilities for plotting\n",
        "\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    img = np.squeeze(img)\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    if predicted_label == true_label:\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]), color=color)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the slider below to determine the number of examples you want to plot. If you get wrong predictions in any model, observe it in the output below (Hint: make max_index = 100 to see the wrong prediction)"
      ],
      "metadata": {
        "id": "9XCmRQI81qNw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TylXFi0quLEw"
      },
      "outputs": [],
      "source": [
        "max_index = 100 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "for index in range(0, max_index):\n",
        "  plt.figure(figsize=(6,3))\n",
        "  plt.subplot(1,2,1)\n",
        "  plot_image(index, predictions, test_labels, test_imgs)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_rrgZ_2P2ZRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Pointers"
      ],
      "metadata": {
        "id": "UcMPs7Sd6iGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "You can use the below line of code to delete the contents (subdirectories and files) of a directory.\n",
        "\n"
      ],
      "metadata": {
        "id": "TGfpIMTr5uRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r '/content/saved_model/'*\n",
        "!rm -r '/content/saved_model/'"
      ],
      "metadata": {
        "id": "2pZBGFKO5hHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the below line of code to delete a file.\n"
      ],
      "metadata": {
        "id": "IIBhDEbV6pyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm '/content/model1.tflite'\n",
        "!rm '/content/model2.tflite'\n",
        "!rm '/content/model3.tflite'"
      ],
      "metadata": {
        "id": "PY6ieGe-6MQh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}